"""
Overfittingì„ í•´ê²°í•˜ê¸° ìœ„í•œ ê°œì„ ëœ DINOv2 ì„¤ì •ë“¤
"""

import os
import copy

# ê¸°ë³¸ ì„¤ì • (í˜„ì¬ ì‚¬ìš©í•œ ê²ƒ)
BASE_CONFIG = {
    'backbone': 'dinov2',
    'img_size': 392,
    'dinov2_size': 'base',
    'pretrained': True,
    'freeze_backbone': True,
    'dropout_rate': 0.1,
}

BASE_TRAIN_CONFIG = {
    'part': 'A',
    'batch_size': 16,
    'stage1_epochs': 30,
    'stage2_epochs': 120,
    'stage1_learning_rate': 1e-3,
    'stage1_weight_decay': 1e-4,
    'stage2_learning_rate': 1e-5,
    'stage2_weight_decay': 1e-4,
    'lr_scheduler': 'cosine',
    'warmup_epochs': 5,
    'early_stopping_patience': 20,
    'grad_clip_norm': 0.5,
    'seed': 42,
    'num_workers': 4,
    'pin_memory': True,
    'log_freq': 10,
}

# =============================================================================
# ì‹¤í—˜ 1: ê°•í™”ëœ ì •ê·œí™” (Regularization++)
# =============================================================================
EXPERIMENT_1_CONFIG = {
    'name': 'dinov2_regularized_v1',
    'description': 'ê°•í™”ëœ ì •ê·œí™”ë¡œ overfitting í•´ê²°',
    'model_config': {
        **BASE_CONFIG,
        'dropout_rate': 0.3,  # 0.1 â†’ 0.3 (3ë°° ì¦ê°€)
    },
    'train_config': {
        **BASE_TRAIN_CONFIG,
        'stage1_weight_decay': 5e-4,  # 1e-4 â†’ 5e-4 (5ë°° ì¦ê°€)
        'stage2_weight_decay': 5e-4,  # Weight decay ê°•í™”
        'early_stopping_patience': 15,  # ë” ë¹ ë¥¸ ì¡°ê¸° ì¢…ë£Œ
        'stage2_epochs': 80,  # í›ˆë ¨ epoch ì¤„ì´ê¸°
    }
}

# =============================================================================
# ì‹¤í—˜ 2: ì‘ì€ ëª¨ë¸ + ê°•í™”ëœ Data Augmentation
# =============================================================================
EXPERIMENT_2_CONFIG = {
    'name': 'dinov2_small_augmented',
    'description': 'ì‘ì€ ëª¨ë¸ + ê°•í•œ Data Augmentation',
    'model_config': {
        **BASE_CONFIG,
        'dinov2_size': 'small',  # base â†’ small (íŒŒë¼ë¯¸í„° ìˆ˜ ì ˆë°˜)
        'dropout_rate': 0.2,
    },
    'train_config': {
        **BASE_TRAIN_CONFIG,
        'batch_size': 24,  # ì‘ì€ ëª¨ë¸ë¡œ ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì¦ê°€
        'stage2_epochs': 100,
        'data_augmentation': 'strong',  # ê°•í•œ augmentation
    }
}

# =============================================================================
# ì‹¤í—˜ 3: ë³´ìˆ˜ì  í•™ìŠµë¥  + ê¸´ Stage 1
# =============================================================================
EXPERIMENT_3_CONFIG = {
    'name': 'dinov2_conservative',
    'description': 'ë³´ìˆ˜ì  í•™ìŠµë¥ ê³¼ ê¸´ Stage 1 í›ˆë ¨',
    'model_config': {
        **BASE_CONFIG,
        'dropout_rate': 0.25,
    },
    'train_config': {
        **BASE_TRAIN_CONFIG,
        'stage1_epochs': 50,  # 30 â†’ 50 (ë” ê¸´ regression head í›ˆë ¨)
        'stage2_epochs': 70,  # ì§§ì€ fine-tuning
        'stage1_learning_rate': 5e-4,  # 1e-3 â†’ 5e-4 (ë” ë³´ìˆ˜ì )
        'stage2_learning_rate': 5e-6,  # 1e-5 â†’ 5e-6 (ë” ë³´ìˆ˜ì )
        'early_stopping_patience': 12,
    }
}

# =============================================================================
# ì‹¤í—˜ 4: ë™ê²°ëœ ë°±ë³¸ (Frozen Backbone)
# =============================================================================
EXPERIMENT_4_CONFIG = {
    'name': 'dinov2_frozen_backbone',
    'description': 'Backbone ì™„ì „ ë™ê²°ë¡œ overfitting ë°©ì§€',
    'model_config': {
        **BASE_CONFIG,
        'freeze_backbone': True,  # Stage 2ì—ì„œë„ ê³„ì† ë™ê²°
        'dropout_rate': 0.15,
    },
    'train_config': {
        **BASE_TRAIN_CONFIG,
        'stage1_epochs': 60,  # ë” ê¸´ Stage 1
        'stage2_epochs': 40,  # ì§§ì€ Stage 2 (ë°±ë³¸ ë™ê²°)
        'stage2_learning_rate': 5e-4,  # ë” ë†’ì€ í•™ìŠµë¥  (regression headë§Œ)
        'freeze_backbone_stage2': True,  # Stage 2ì—ì„œë„ ë°±ë³¸ ë™ê²°
    }
}

# =============================================================================
# ì‹¤í—˜ 5: ê· í˜•ì¡íŒ ì ‘ê·¼ë²•
# =============================================================================
EXPERIMENT_5_CONFIG = {
    'name': 'dinov2_balanced',
    'description': 'ëª¨ë“  ê¸°ë²•ì„ ì ì ˆíˆ ì¡°í•©í•œ ê· í˜•ì¡íŒ ì ‘ê·¼',
    'model_config': {
        **BASE_CONFIG,
        'dropout_rate': 0.2,
    },
    'train_config': {
        **BASE_TRAIN_CONFIG,
        'batch_size': 20,  # ì•½ê°„ í° ë°°ì¹˜
        'stage1_epochs': 40,
        'stage2_epochs': 60,
        'stage1_learning_rate': 7e-4,
        'stage2_learning_rate': 7e-6,
        'stage1_weight_decay': 3e-4,
        'stage2_weight_decay': 3e-4,
        'early_stopping_patience': 15,
        'grad_clip_norm': 0.3,  # ë” ê°•í•œ gradient clipping
    }
}

# =============================================================================
# ì‹¤í—˜ 6: Label Smoothing + Mixup (ê³ ê¸‰ ê¸°ë²•)
# =============================================================================
EXPERIMENT_6_CONFIG = {
    'name': 'dinov2_advanced_reg',
    'description': 'Label smoothingê³¼ Mixupì„ ì ìš©í•œ ê³ ê¸‰ ì •ê·œí™”',
    'model_config': {
        **BASE_CONFIG,
        'dropout_rate': 0.15,
    },
    'train_config': {
        **BASE_TRAIN_CONFIG,
        'stage2_epochs': 80,
        'label_smoothing': 0.1,  # Label smoothing
        'mixup_alpha': 0.2,  # Mixup augmentation
        'early_stopping_patience': 18,
    }
}

EXPERIMENT_7_CONFIG = {
'name': 'dinov2_max_performance_fixed',
    'description': 'ì˜¤ë²„í”¼íŒ… í•´ê²°ëœ ê³ ì„±ëŠ¥ ì„¤ì • - ê°•í™”ëœ ì •ê·œí™”',
    'model_config': {
        'backbone': 'dinov2',
        'img_size': 448,  # 448 â†’ 392 (ë©”ëª¨ë¦¬ì™€ ì˜¤ë²„í”¼íŒ… ì™„í™”)
        'dinov2_size': 'large',  # large â†’ base (ëª¨ë¸ í¬ê¸° ì¶•ì†Œë¡œ ì˜¤ë²„í”¼íŒ… ì™„í™”)
        'pretrained': True,
        'freeze_backbone': True,  # False â†’ True (Stage 1ì—ì„œ ë°±ë³¸ ë™ê²°)
        'dropout_rate': 0.4,  # 0.15 â†’ 0.4 (ë§¤ìš° ê°•í•œ ë“œë¡­ì•„ì›ƒ)
    },
    'train_config': {
        'part': 'A',
        'batch_size': 24,  # 32 â†’ 24 (ì•½ê°„ ì¶•ì†Œ)

        # í›¨ì”¬ ë³´ìˆ˜ì ì¸ í›ˆë ¨ ê¸¸ì´
        'stage1_epochs': 40,  # 60 â†’ 40
        'stage2_epochs': 60,  # 150 â†’ 60 (ë§¤ìš° ì§§ê²Œ)

        # ë§¤ìš° ë³´ìˆ˜ì ì¸ í•™ìŠµë¥ 
        'stage1_learning_rate': 1e-4,  # 3e-4 â†’ 1e-4 (ë” ë‚®ê²Œ)
        'stage2_learning_rate': 5e-7,  # 1e-6 â†’ 5e-7 (ë”ë”ìš± ë‚®ê²Œ)

        # ë§¤ìš° ê°•í•œ ì •ê·œí™”
        'stage1_weight_decay': 5e-3,  # 1e-3 â†’ 5e-3 (5ë°° ì¦ê°€)
        'stage2_weight_decay': 5e-3,  # ë§¤ìš° ê°•í•œ weight decay

        # Stage 2ì—ì„œë„ ë°±ë³¸ ë™ê²° ì˜µì…˜ ì¶”ê°€
        'freeze_backbone_stage2': True,  # ìƒˆë¡œ ì¶”ê°€: Stage 2ì—ì„œë„ ë°±ë³¸ ë™ê²°

        'lr_scheduler': 'cosine',
        'warmup_epochs': 8,  # 10 â†’ 8
        'early_stopping_patience': 12,  # 25 â†’ 12 (ë” ë¹ ë¥¸ ì¡°ê¸° ì¢…ë£Œ)
        'grad_clip_norm': 0.1,  # 0.3 â†’ 0.1 (ë” ê°•í•œ gradient clipping)
        'seed': 42,
        'num_workers': 6,  # 8 â†’ 6
        'pin_memory': True,
        'log_freq': 10,

        # ì •ê·œí™” ê¸°ë²•ë“¤ ê°•í™”
        'data_augmentation': 'strong',
        'mixup_alpha': 0.3,  # 0.1 â†’ 0.3 (ë” ê°•í•œ mixup)
        'label_smoothing': 0.15,  # 0.05 â†’ 0.15 (ë” ê°•í•œ label smoothing)
    }
}

# =============================================================================
# ì‹¤í—˜ 8: ë©”ëª¨ë¦¬ ê·¹í•œ ë„ì „ (Giant ëª¨ë¸)
# =============================================================================
EXPERIMENT_8_CONFIG = {
    'name': 'dinov2_giant_challenge',
    'description': 'ë©”ëª¨ë¦¬ í•œê³„ ë„ì „ - Giant ëª¨ë¸',
    'model_config': {
        'backbone': 'dinov2',
        'img_size': 392,  # GiantëŠ” ë©”ëª¨ë¦¬ ë§ì´ ì¨ì„œ í•´ìƒë„ ì¡°ê¸ˆ ë‚®ì¶¤
        'dinov2_size': 'giant',  # ê°€ì¥ í° ëª¨ë¸
        'pretrained': True,
        'freeze_backbone': True,  # GiantëŠ” freezeí•´ì„œ ë©”ëª¨ë¦¬ ì ˆì•½
        'dropout_rate': 0.2,
    },
    'train_config': {
        'part': 'A',
        'batch_size': 16,  # Giant ëª¨ë¸ì´ë¼ ë°°ì¹˜ í¬ê¸° ì¡°ì •

        'stage1_epochs': 80,  # ë§¤ìš° ê¸´ stage1 (ë°±ë³¸ freeze)
        'stage2_epochs': 60,  # ì§§ì€ stage2

        'stage1_learning_rate': 5e-4,
        'stage2_learning_rate': 5e-7,  # ë§¤ìš° ë‚®ì€ í•™ìŠµë¥ 

        'stage1_weight_decay': 5e-4,
        'stage2_weight_decay': 5e-4,

        'freeze_backbone_stage2': True,  # Stage2ì—ì„œë„ ë°±ë³¸ ë™ê²°

        'lr_scheduler': 'cosine',
        'warmup_epochs': 15,
        'early_stopping_patience': 20,
        'grad_clip_norm': 0.5,
        'seed': 42,
        'num_workers': 6,
        'pin_memory': True,
        'log_freq': 10,

        'data_augmentation': 'strong',
    }
}

# ëª¨ë“  ì‹¤í—˜ ì„¤ì • ë¦¬ìŠ¤íŠ¸
ALL_EXPERIMENTS = [
    EXPERIMENT_1_CONFIG,
    EXPERIMENT_2_CONFIG,
    EXPERIMENT_3_CONFIG,
    EXPERIMENT_4_CONFIG,
    EXPERIMENT_5_CONFIG,
    EXPERIMENT_6_CONFIG,
    EXPERIMENT_7_CONFIG,
    EXPERIMENT_8_CONFIG
]


def print_experiment_summary():
    """ëª¨ë“  ì‹¤í—˜ ì„¤ì • ìš”ì•½ ì¶œë ¥"""
    print("ğŸ§ª OVERFITTING í•´ê²°ì„ ìœ„í•œ ì‹¤í—˜ ì„¤ì •ë“¤")
    print("=" * 80)

    for i, exp in enumerate(ALL_EXPERIMENTS, 1):
        print(f"\nì‹¤í—˜ {i}: {exp['name']}")
        print(f"ì„¤ëª…: {exp['description']}")

        print("ì£¼ìš” ë³€ê²½ì‚¬í•­:")
        model_changes = []
        train_changes = []

        # ëª¨ë¸ ì„¤ì • ë³€ê²½ì‚¬í•­
        for key, value in exp['model_config'].items():
            if key in BASE_CONFIG and BASE_CONFIG[key] != value:
                model_changes.append(f"  {key}: {BASE_CONFIG[key]} â†’ {value}")

        # í›ˆë ¨ ì„¤ì • ë³€ê²½ì‚¬í•­
        for key, value in exp['train_config'].items():
            if key in BASE_TRAIN_CONFIG and BASE_TRAIN_CONFIG[key] != value:
                train_changes.append(f"  {key}: {BASE_TRAIN_CONFIG[key]} â†’ {value}")
            elif key not in BASE_TRAIN_CONFIG:
                train_changes.append(f"  {key}: {value} (ìƒˆë¡œ ì¶”ê°€)")

        if model_changes:
            print("ğŸ“Š ëª¨ë¸ ì„¤ì •:")
            for change in model_changes:
                print(change)

        if train_changes:
            print("ğŸ‹ï¸ í›ˆë ¨ ì„¤ì •:")
            for change in train_changes:
                print(change)

        print(f"ğŸ’» ì‹¤í–‰ ëª…ë ¹ì–´:")
        print(f"python train_dinov2_improved.py --experiment {i}")


def get_experiment_config(experiment_id):
    """ì‹¤í—˜ IDë¡œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°"""
    if 1 <= experiment_id <= len(ALL_EXPERIMENTS):
        return ALL_EXPERIMENTS[experiment_id - 1]
    else:
        raise ValueError(f"Invalid experiment ID: {experiment_id}. Choose 1-{len(ALL_EXPERIMENTS)}")


# ê¶Œì¥ ì‹¤í—˜ ìˆœì„œ
RECOMMENDED_ORDER = [
    (1, "ê°•í™”ëœ ì •ê·œí™”", "ê°€ì¥ ê°„ë‹¨í•˜ê³  íš¨ê³¼ì ì¸ ë°©ë²•"),
    (3, "ë³´ìˆ˜ì  í•™ìŠµë¥ ", "ì•ˆì •ì ì´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë°©ë²•"),
    (5, "ê· í˜•ì¡íŒ ì ‘ê·¼", "ì—¬ëŸ¬ ê¸°ë²•ì„ ì¡°í•©í•œ ì¢…í•©ì  ì ‘ê·¼"),
    (2, "ì‘ì€ ëª¨ë¸", "ë¹ ë¥¸ ì‹¤í—˜ê³¼ ë¹„êµìš©"),
]


def print_recommendations():
    """ê¶Œì¥ ì‹¤í—˜ ìˆœì„œ ì¶œë ¥"""
    print("\nğŸ¯ ê¶Œì¥ ì‹¤í—˜ ìˆœì„œ:")
    print("=" * 50)

    for exp_id, name, reason in RECOMMENDED_ORDER:
        print(f"{exp_id}. {name}")
        print(f"   ì´ìœ : {reason}")
        print(f"   ì‹¤í–‰: python train_dinov2_improved.py --experiment {exp_id}")
        print()


if __name__ == '__main__':
    print_experiment_summary()
    print_recommendations()